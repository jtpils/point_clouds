{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\">Imports</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2\">Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Quaternion-functions:\" data-toc-modified-id=\"Quaternion-functions:-2.1\">Quaternion functions:</a></span></li><li><span><a href=\"#General-purpose-ops-(Utils)\" data-toc-modified-id=\"General-purpose-ops-(Utils)-2.2\">General purpose ops (Utils)</a></span></li></ul></li><li><span><a href=\"#Projection-module\" data-toc-modified-id=\"Projection-module-3\">Projection module</a></span><ul class=\"toc-item\"><li><span><a href=\"#Camera-transformation\" data-toc-modified-id=\"Camera-transformation-3.1\">Camera transformation</a></span></li><li><span><a href=\"#Voxels-from-point-clouds\" data-toc-modified-id=\"Voxels-from-point-clouds-3.2\">Voxels from point clouds</a></span></li><li><span><a href=\"#Voxels-smoothing\" data-toc-modified-id=\"Voxels-smoothing-3.3\">Voxels smoothing</a></span></li><li><span><a href=\"#Projection-and-point-cloud-dropout\" data-toc-modified-id=\"Projection-and-point-cloud-dropout-3.4\">Projection and point cloud dropout</a></span></li></ul></li><li><span><a href=\"#Models\" data-toc-modified-id=\"Models-4\">Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Common\" data-toc-modified-id=\"Common-4.1\">Common</a></span></li><li><span><a href=\"#Point-cloud-decoder\" data-toc-modified-id=\"Point-cloud-decoder-4.2\">Point cloud decoder</a></span></li><li><span><a href=\"#Pose-decoder\" data-toc-modified-id=\"Pose-decoder-4.3\">Pose decoder</a></span></li><li><span><a href=\"#SupervisedModel\" data-toc-modified-id=\"SupervisedModel-4.4\">SupervisedModel</a></span></li><li><span><a href=\"#Unsupervised-model\" data-toc-modified-id=\"Unsupervised-model-4.5\">Unsupervised model</a></span></li></ul></li><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-5\">Data</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-6\">Training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Overfit-one-batch\" data-toc-modified-id=\"Overfit-one-batch-6.1\">Overfit one batch</a></span></li><li><span><a href=\"#Training-loop\" data-toc-modified-id=\"Training-loop-6.2\">Training loop</a></span></li><li><span><a href=\"#Train-models\" data-toc-modified-id=\"Train-models-6.3\">Train models</a></span></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-7\">Evaluation</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T11:45:30.563026Z",
     "start_time": "2019-12-18T11:45:30.555576Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import math\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading, visualization and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T11:45:31.648143Z",
     "start_time": "2019-12-18T11:45:30.902065Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "from scipy.spatial.transform import Rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T12:04:47.184746Z",
     "start_time": "2019-12-18T12:04:47.175716Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as T\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "General tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quaternion functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T11:45:38.469011Z",
     "start_time": "2019-12-18T11:45:38.445122Z"
    }
   },
   "outputs": [],
   "source": [
    "def points2quat(v):\n",
    "    \"Convert xyz points to quaternions\"\n",
    "    assert len(v.shape) == 3\n",
    "    assert v.size(-1) == 3\n",
    "    return F.pad(v, (1, 0, 0, 0))\n",
    "\n",
    "def quatmul(q1, q2):\n",
    "    \"Multiply quaternions\"\n",
    "    w1, x1, y1, z1 = torch.unbind(q1, dim=-1)\n",
    "    w2, x2, y2, z2 = torch.unbind(q2, dim=-1)\n",
    "\n",
    "    w = w1 * w2 - x1 * x2 - y1 * y2 - z1 * z2\n",
    "    x = w1 * x2 + x1 * w2 + y1 * z2 - z1 * y2\n",
    "    y = w1 * y2 + y1 * w2 + z1 * x2 - x1 * z2\n",
    "    z = w1 * z2 + z1 * w2 + x1 * y2 - y1 * x2\n",
    "    return torch.stack([w, x, y, z], dim=-1)\n",
    "\n",
    "def quatconj(q):\n",
    "    \"Conjugate of quaternion\"\n",
    "    m = q.new(4).fill_(-1)\n",
    "    m[0] = 1.0\n",
    "    return q * m \n",
    "\n",
    "def quatrot(v, q, inverse=False):\n",
    "    \"Rotate points v [b, n, 3] with quaternions q [b, 4]\"\n",
    "    q = F.normalize(q, dim=-1)\n",
    "    q = q[:, None, :]\n",
    "    q_ = quatconj(q)\n",
    "    v = points2quat(v)\n",
    "\n",
    "    if inverse:\n",
    "        wxyz = quatmul(quatmul(q_, v), q)\n",
    "    else:\n",
    "        wxyz = quatmul(quatmul(q, v), q_)\n",
    "        \n",
    "    if len(wxyz.shape) == 2:\n",
    "        wxyz = wxyz.unsqueeze(0)\n",
    "\n",
    "    return wxyz[:, :, 1:4]\n",
    "\n",
    "\n",
    "def quat_from_campos(pos):\n",
    "    \"Convert blender camera format `pos` to torch tensor quaternion [w, x, y, z]\"\n",
    "    cx, cy, cz = pos[0]\n",
    "    camDist = math.sqrt(cx * cx + cy * cy + cz * cz)\n",
    "    cx = cx / camDist\n",
    "    cy = cy / camDist\n",
    "    cz = cz / camDist\n",
    "    t = math.sqrt(cx * cx + cy * cy)\n",
    "    tx = cx / t\n",
    "    ty = cy / t\n",
    "    yaw = math.acos(tx)\n",
    "    if ty > 0:\n",
    "        yaw = 2 * math.pi - yaw\n",
    "\n",
    "    roll = 0\n",
    "    pitch = math.asin(cz)\n",
    "    yaw = yaw + math.pi\n",
    "\n",
    "    quat = Rotation.from_euler(\"yzx\", [yaw, pitch, roll]).as_quat()\n",
    "    quat = np.r_[quat[-1], quat[:-1]]\n",
    "\n",
    "    return torch.tensor(quat.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General purpose ops (Utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T11:45:38.751978Z",
     "start_time": "2019-12-18T11:45:38.743696Z"
    }
   },
   "outputs": [],
   "source": [
    "def repeat_tensor_batch(tensor, times):\n",
    "    \"Repeat tensor `times` times for each element in batch\"\n",
    "    if tensor is None: return\n",
    "\n",
    "    data_shape = tensor.shape[1:]\n",
    "    repeats = [1, times] + [1] * len(data_shape)\n",
    "\n",
    "    expanded = tensor.unsqueeze(1).repeat(*repeats)\n",
    "    return expanded.view(-1, *data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T12:41:16.340977Z",
     "start_time": "2019-12-18T12:41:16.328348Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_projections_img(model, imgs, poses, masks):\n",
    "    \"Generate grid with model projections, gt projections and input images\"\n",
    "    device = next(model.parameters()).device\n",
    "    proj, *_ = model(imgs[0].unsqueeze(0).to(device), poses.to(device))\n",
    "    proj = proj.detach().cpu()\n",
    "\n",
    "    grid = torch.cat([\n",
    "        F.interpolate(imgs, scale_factor=1/2, mode='bilinear', align_corners=True),\n",
    "        F.interpolate(masks.unsqueeze(1), scale_factor=1/2, mode='bilinear', align_corners=True).repeat(1, 3, 1, 1),\n",
    "        proj.unsqueeze(1).repeat(1, 3, 1, 1),\n",
    "    ])\n",
    "    \n",
    "    grid = make_grid(grid, nrow=imgs.size(0))\n",
    "    return F.interpolate(grid.unsqueeze(0), scale_factor=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection module\n",
    "Most of the module is implemented as functions, as almost all operations don't have learnable parameters. I tried to set default hyperparameter values as mentioned in paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera transformation \n",
    "camera had same $z$ coordinate with different angles and $x$, $y$ positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T11:45:39.676553Z",
     "start_time": "2019-12-18T11:45:39.668334Z"
    }
   },
   "outputs": [],
   "source": [
    "def pc_camera_transform(pc, rotation, focal_lenght=1.875, camera_distance=2.0):\n",
    "    \"Transform pontcloud `pc` to camera coordinates with `rotation`\"\n",
    "    \n",
    "    pc = quatrot(pc, rotation)\n",
    "    zs, ys, xs = torch.unbind(pc, dim=2)\n",
    "    \n",
    "    xs = xs * focal_lenght / (zs + camera_distance)\n",
    "    ys = ys * focal_lenght / (zs + camera_distance)\n",
    "\n",
    "    return torch.stack([zs, ys, xs], dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voxels from point clouds\n",
    "\n",
    "Fit point cloud to 3d grid with trilinear interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T11:45:40.259273Z",
     "start_time": "2019-12-18T11:45:40.242203Z"
    }
   },
   "outputs": [],
   "source": [
    "def pc_voxels(pc, size=64, eps=1e-6):\n",
    "    \"Create voxels of `[size]*3` from pointcloud `pc`\"\n",
    "    # save for later\n",
    "    vox_size = pc.new(3).fill_(size)\n",
    "    bs = pc.size(0)\n",
    "    n = pc.size(1)\n",
    "    \n",
    "    # check borders\n",
    "    valid = ((pc < 0.5 - eps) & (pc > -0.5 + eps)).all(dim=-1).view(-1)\n",
    "    grid = (pc + 0.5) * (vox_size - 1)\n",
    "    grid_floor = grid.floor()\n",
    "\n",
    "    grid_idxs = grid_floor.long()\n",
    "    batch_idxs = torch.arange(bs)[:, None, None].repeat(1, n, 1).to(pc.device)\n",
    "    # idxs of form [batch, z, y, x] where z, y, x discretized indecies in voxel\n",
    "    idxs = torch.cat([batch_idxs, grid_idxs], dim=-1).view(-1, 4)\n",
    "    idxs = idxs[valid]\n",
    "\n",
    "    # trilinear interpolation\n",
    "    r = grid - grid_floor\n",
    "    rr = [1. - r, r]\n",
    "    voxels = []\n",
    "    voxels_t = pc.new(bs, size, size, size).fill_(0)\n",
    "\n",
    "    def trilinear_interp(pos):\n",
    "        update = rr[pos[0]][..., 0] * rr[pos[1]][..., 1] * rr[pos[2]][..., 2]\n",
    "        update = update.view(-1)[valid]\n",
    "        \n",
    "        shift_idxs = torch.LongTensor([[0] + pos]).to(pc.device)\n",
    "        shift_idxs = shift_idxs.repeat(idxs.size(0), 1)\n",
    "        update_idxs = idxs + shift_idxs\n",
    "        valid_shift = update_idxs < size\n",
    "        voxels_t.index_put_(torch.unbind(update_idxs, dim=1), update, accumulate=True)\n",
    "\n",
    "        return voxels_t\n",
    "        \n",
    "    \n",
    "    for k in range(2):\n",
    "        for j in range(2):\n",
    "            for i in range(2):\n",
    "                voxels.append(trilinear_interp([k, j, i]))\n",
    "    \n",
    "    return torch.stack(voxels).sum(dim=0).clamp(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voxels smoothing\n",
    "\n",
    "Fast gaussian smoothing of a voxel. There was an issue with speed of pytorch conv3d backward pass in this operation. I solved it by reordering batch and channels dimensions and using groups. It turned out to be 10x faster. Batch parallelization of `conv3d` vs channel parallelization (second is faster in this case with $1$ channel in voxel and $\\approx 40$ voxels per batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T11:45:40.687961Z",
     "start_time": "2019-12-18T11:45:40.674113Z"
    }
   },
   "outputs": [],
   "source": [
    "def smoothing_kernel(sigma, kernel_size=21):\n",
    "    \"Generate 3 separate gaussian kernels with `sigma` stddev\"\n",
    "    x = torch.arange(-kernel_size//2 + 1., kernel_size//2 + 1., device=sigma.device)\n",
    "    kernel_1d = torch.exp(-x**2 / (2. * sigma**2))\n",
    "    kernel_1d = kernel_1d / kernel_1d.sum()\n",
    "\n",
    "    k1 = kernel_1d.view(1, 1, 1, 1, -1)\n",
    "    k2 = kernel_1d.view(1, 1, 1, -1, 1)\n",
    "    k3 = kernel_1d.view(1, 1, -1, 1, 1)\n",
    "    return [k1, k2, k3]\n",
    "\n",
    "def voxels_smooth(voxels, kernels, scale=None):\n",
    "    \"Apply gaussian blur to voxels with separable `kernels` then `scale`\"\n",
    "    assert isinstance(kernels, list)\n",
    "\n",
    "    # add fake channel for convs\n",
    "    bs = voxels.size(0)\n",
    "    voxels = voxels.unsqueeze(0)\n",
    "\n",
    "    for k in kernels:\n",
    "        # add padding for kernel dimension\n",
    "        padding = [0] * 3\n",
    "        padding[np.argmax(k.shape) - 2] = max(k.shape) // 2\n",
    "\n",
    "        voxels = F.conv3d(voxels, k.repeat(bs, 1, 1, 1, 1), stride=1, padding=padding, groups=bs)\n",
    "\n",
    "    voxels = voxels.squeeze(0)\n",
    "\n",
    "    if scale is not None:\n",
    "        voxels = voxels * scale.view(-1, 1, 1, 1)\n",
    "        voxels = voxels.clamp(0, 1)\n",
    "\n",
    "    return voxels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection and point cloud dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T11:45:41.104252Z",
     "start_time": "2019-12-18T11:45:41.093470Z"
    }
   },
   "outputs": [],
   "source": [
    "def drc_prob(voxels, clip_val=1e-5):\n",
    "    \"Compute termination probabilities from part 4 https://arxiv.org/pdf/1810.09381.pdf\"\n",
    "    inp = voxels.permute(1, 0, 2, 3)\n",
    "    inp = inp.clamp(clip_val, 1.0 - clip_val)\n",
    "    zero = voxels.new(1, inp.size(1), inp.size(2), inp.size(3)).fill_(clip_val)\n",
    "\n",
    "    y = torch.log(inp)\n",
    "    x = torch.log(1 - inp)\n",
    "\n",
    "    r = torch.cumsum(x, dim=0)\n",
    "    p1 = torch.cat([zero, r], dim=0)\n",
    "    p2 = torch.cat([y, zero], dim=0)\n",
    "\n",
    "    p = p1 + p2\n",
    "    return torch.exp(p).permute(1, 0, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class, which handles projection from point cloud(s) to images of this ponit cloud(s) at different rotatoins. The result is $N_{\\mathrm{batch}} \\cdot N_{\\mathrm{views}} \\times N_{\\mathrm{img}} \\times N_{\\mathrm{img}}$, so each point cloud is rotated multiple times (read: repeated for each view in batch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T11:45:41.442049Z",
     "start_time": "2019-12-18T11:45:41.433034Z"
    }
   },
   "outputs": [],
   "source": [
    "class Projection(nn.Module):\n",
    "    \"Diffefentiable point cloud projection module\"\n",
    "    def __init__(self, vox_size=64, smooth_ks=21, smooth_sigma=3.0):\n",
    "        super().__init__()\n",
    "        self.vox_size = vox_size\n",
    "        self.ks = smooth_ks\n",
    "        self.register_buffer('sigma', torch.tensor(smooth_sigma))\n",
    "\n",
    "    def forward(self, pc, rotation, scale=None):\n",
    "        \"Project points `pc` to camera givne by `transform`\"\n",
    "        pc = pc_camera_transform(pc, rotation)\n",
    "        voxels = pc_voxels(pc, self.vox_size)\n",
    "        smooth = voxels_smooth(voxels, kernels=smoothing_kernel(self.sigma, self.ks), scale=scale)\n",
    "\n",
    "        prob = drc_prob(smooth)\n",
    "        proj = prob[:, :-1].sum(1).flip(1)\n",
    "        return proj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point cloud dropout keeps only `keep_prob` points in each point cloud of a batch (different points for each example in one batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T11:45:41.802634Z",
     "start_time": "2019-12-18T11:45:41.792696Z"
    }
   },
   "outputs": [],
   "source": [
    "class PointCloudDropout(nn.Module):\n",
    "    \"Drop random portions of pointclouds `pc`\"\n",
    "    def __init__(self, keep_prob=0.07):\n",
    "        super().__init__()\n",
    "        self.keep_prob = keep_prob\n",
    "        \n",
    "    def forward(self, pc):\n",
    "        bs, n_points = pc.size(0), pc.size(1)\n",
    "        n_keep = math.ceil(n_points * self.keep_prob)\n",
    "\n",
    "        batch_idxs = repeat_tensor_batch(torch.arange(bs), n_keep)\n",
    "        point_idxs = torch.cat([torch.randperm(n_points)[:n_keep] for i in range(bs)])\n",
    "\n",
    "        return pc[batch_idxs, point_idxs].view(bs, n_keep, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Both camera supervised and unsupervised models are implemented below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common \n",
    "\n",
    "blocks used in modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T11:45:42.615219Z",
     "start_time": "2019-12-18T11:45:42.605741Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_block(in_ch, out_ch, ks=3, stride=1, padding=1, bn=True, act=True):\n",
    "    \"Basic convolutional block with relu and batchnorm\"\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_ch, out_ch, ks, stride, padding, bias=not bn),\n",
    "        nn.ReLU(True) if act else nn.Identity(),\n",
    "        nn.BatchNorm2d(out_ch) if bn else nn.Identity(),\n",
    "    )\n",
    "\n",
    "def pose_predictor(n_ft):\n",
    "    \"Pose predictor with 2 hidden layers\"\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(n_ft, n_ft),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(n_ft, n_ft),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(n_ft, 4),\n",
    "    )\n",
    "\n",
    "def weight_init(m):\n",
    "    \"Kaiming normal init for relu with slope 0 for linear and conv layers\"\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight.data, a=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder is almost as in original paper, but with batch normalization and ReLU activations with kaiming normal initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T11:45:43.278681Z",
     "start_time": "2019-12-18T11:45:43.269051Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Encodes input images\"\n",
    "    def __init__(self, img_size, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.convs = nn.Sequential(                       \n",
    "            conv_block(3, 16,  ks=5, stride=2, padding=2),\n",
    "            conv_block(16, 16, ks=3, stride=2),            \n",
    "            conv_block(16, 16, ks=3, stride=1),          \n",
    "            conv_block(16, 16, ks=3, stride=2),           \n",
    "            conv_block(16, 16, ks=3, stride=1),\n",
    "            conv_block(16, 16, ks=3, stride=2),           \n",
    "            conv_block(16, 16, ks=3, stride=1),\n",
    "            conv_block(16, 16, ks=3, stride=2),          \n",
    "            conv_block(16, 16, ks=3, stride=1),\n",
    "        )\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 16, 1024, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, 1024),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        conv_features = self.convs(img)\n",
    "        features = self.features(conv_features)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point cloud decoder \n",
    "\n",
    "used to generate point clouds from hidden vector of encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T11:45:44.108899Z",
     "start_time": "2019-12-18T11:45:44.101377Z"
    }
   },
   "outputs": [],
   "source": [
    "class PointCloudDecoder(nn.Module):\n",
    "    def __init__(self, num_points, hidden_dim=1024, predict_scale=True):\n",
    "        super().__init__()\n",
    "        self.num_points = num_points\n",
    "        self.predict_scale = predict_scale\n",
    "        self.pc_decoder = nn.Linear(hidden_dim, num_points * 3)\n",
    "        self.scale_decoder = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"Transform hidden vector to pointcloud\"\n",
    "        # predict pointcloud\n",
    "        pc = self.pc_decoder(z)\n",
    "        pc = pc.view(-1, self.num_points, 3)\n",
    "        pc = torch.tanh(pc) / 2.0\n",
    "\n",
    "        scale = None\n",
    "        if self.predict_scale:\n",
    "            scale = self.scale_decoder(z)\n",
    "            scale = torch.sigmoid(scale)\n",
    "\n",
    "        return pc, scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pose branch `hidden_dim` is slightly bigger than in paper. Pose decoder in `eval` mode returns one pose for each example in batch. In `train` mode it returns `num_candidates` poses for each example (one additional pose is student prediction). In this case poses are repeated in batch dimension like `num_candidates` poses for first example, ..., `num_candidates` poses for nth example. In this setting we can use `repeat_tensor_batch` to replicate point clouds for each view and get projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T11:45:45.449065Z",
     "start_time": "2019-12-18T11:45:45.438876Z"
    }
   },
   "outputs": [],
   "source": [
    "class PoseDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_candidates=4):\n",
    "        \"Predict `num_candidates` pose candidates for each example in batch\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Shared part\n",
    "        self.ensemble = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.predictors = nn.ModuleList([pose_predictor(hidden_dim) for i in range(num_candidates)])\n",
    "\n",
    "        self.student = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(True),\n",
    "            pose_predictor(hidden_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"Transform hidden vector to rotation quaternions\"\n",
    "        student_quat = self.student(z)\n",
    "\n",
    "        if not self.training:\n",
    "            return student_quat\n",
    "        \n",
    "        ensemble = self.ensemble(z)\n",
    "        all_quats = [p(ensemble) for p in self.predictors]\n",
    "        ensemble_quat = torch.cat(all_quats, dim=-1).view(-1, 4)\n",
    "\n",
    "        return torch.cat([ensemble_quat, student_quat], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SupervisedModel\n",
    "\n",
    "`SupervisedModel` uses camera supervision and only predicts and projects point clouds to different cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T12:39:42.059673Z",
     "start_time": "2019-12-18T12:39:42.053722Z"
    }
   },
   "outputs": [],
   "source": [
    "a, *_ = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T12:39:43.485614Z",
     "start_time": "2019-12-18T12:39:43.470601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T12:35:05.833446Z",
     "start_time": "2019-12-18T12:35:05.814854Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupervisedModel(nn.Module):\n",
    "    \"Basic model\"\n",
    "    def __init__(\n",
    "        self, img_size=128, hidden_dim=1024, num_points=8000, \n",
    "        vox_size=64, smooth_sigma=3.0, predict_scale=True, keep_prob=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(img_size, hidden_dim)\n",
    "        self.decoder = PointCloudDecoder(num_points, hidden_dim, predict_scale)\n",
    "        self.pc_dropout = PointCloudDropout(keep_prob)\n",
    "        self.pc_projection = Projection(vox_size, smooth_sigma=smooth_sigma)\n",
    "\n",
    "        self.encoder.apply(weight_init)\n",
    "        self.decoder.apply(weight_init)\n",
    "\n",
    "    def forward(self, imgs, poses):\n",
    "        \"Generate new view of `imgs` from `cameras` using differentiable projection\"\n",
    "        bs = imgs.size(0)\n",
    "        num_views = poses.size(0) // bs\n",
    "\n",
    "        z = self.encoder(imgs)\n",
    "        pc, scale = self.decoder(z)\n",
    "\n",
    "        pc    = repeat_tensor_batch(self.pc_dropout(pc), num_views)\n",
    "        scale = repeat_tensor_batch(scale, num_views)\n",
    "        proj  = self.pc_projection(pc, poses, scale)\n",
    "\n",
    "        return proj\n",
    "    \n",
    "\n",
    "class SupervisedLoss(nn.Module):\n",
    "    \"Mse loss / 2\"\n",
    "    def forward(self, proj, masks, **kwargs):\n",
    "        proj = F.interpolate(proj.unsqueeze(0), scale_factor=2, mode='bilinear', align_corners=True).squeeze()\n",
    "        return dict(full_loss=F.mse_loss(proj, masks, reduction='sum') / (2 * proj.size(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T12:38:45.562322Z",
     "start_time": "2019-12-18T12:38:45.537400Z"
    }
   },
   "outputs": [],
   "source": [
    "class UnsupervisedModel(nn.Module):\n",
    "    \"Unsupervised model with ensemble of pose predictors\"\n",
    "    def __init__(self, img_size=128, vox_size=64, \n",
    "                 z_dim=1024, pose_dim=128, \n",
    "                 num_points=8000, num_candidates=4, num_views=5):\n",
    "        super().__init__()\n",
    "        self.num_views = num_views\n",
    "        self.num_candidates = num_candidates\n",
    "\n",
    "        self.encoder = Encoder(img_size, z_dim)\n",
    "        self.pc_decoder = PointCloudDecoder(num_points, hidden_dim=z_dim)\n",
    "        self.pc_dropout = PointCloudDropout()\n",
    "        self.pc_projection = Projection(vox_size)\n",
    "        self.pose_decoder = PoseDecoder(input_dim=z_dim, hidden_dim=pose_dim, num_candidates=num_candidates)\n",
    "\n",
    "    def forward(self, imgs, poses):\n",
    "        z, z_p = self.encoder(imgs), self.encoder(poses)\n",
    "        pc, scale = self.pc_decoder(z)\n",
    "        poses = self.pose_decoder(z_p)\n",
    "\n",
    "        # No ensemble on inference\n",
    "        if not self.training:\n",
    "            bs = imgs.size(0)\n",
    "            pc    = repeat_tensor_batch(self.pc_dropout(pc), self.num_views)\n",
    "            scale = repeat_tensor_batch(scale, self.num_views)\n",
    "            proj  = self.pc_projection(pc, poses, scale)\n",
    "            return proj, poses\n",
    "\n",
    "        bs = imgs.size(0) * self.num_views\n",
    "        ensemble_poses, student_poses = poses[:-bs], poses[-bs:]\n",
    "\n",
    "        pc    = repeat_tensor_batch(self.pc_dropout(pc), self.num_candidates * self.num_views)\n",
    "        scale = repeat_tensor_batch(scale, self.num_candidates * self.num_views)\n",
    "        proj = self.pc_projection(pc, ensemble_poses, scale)\n",
    "\n",
    "        return proj, ensemble_poses, student_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T13:06:05.791063Z",
     "start_time": "2019-12-18T13:06:05.770579Z"
    }
   },
   "outputs": [],
   "source": [
    "class UnsupervisedLoss(nn.Module):\n",
    "    \"Loss combines projection losses for ensemble and student loss\"\n",
    "    def __init__(self, num_candidates=4, student_weight=20.0):\n",
    "        super().__init__()\n",
    "        self.student_weight = student_weight\n",
    "        self.num_candidates = num_candidates\n",
    "    \n",
    "    def forward(self, pred, masks, training):\n",
    "        proj, *poses = pred\n",
    "        proj = F.interpolate(proj.unsqueeze(0), scale_factor=2, mode='bilinear', align_corners=True).squeeze()\n",
    "\n",
    "        if not training:\n",
    "            return dict(projection_loss=F.mse_loss(proj, masks, reduction='sum') / proj.size(0))\n",
    "        \n",
    "        ensemble_poses, student_poses = poses\n",
    "        masks = repeat_tensor_batch(masks, self.num_candidates)\n",
    "\n",
    "        projection_loss = F.mse_loss(proj, masks, reduction='none')\n",
    "        projection_loss = projection_loss.sum((1,2)).view(-1, self.num_candidates)\n",
    "        min_idxs = projection_loss.argmin(dim=-1)\n",
    "        batch_idxs = torch.arange(min_idxs.size(0), device=min_idxs.device)\n",
    "        \n",
    "        # Student loss\n",
    "        min_projection_loss = projection_loss[batch_idxs, min_idxs].sum() / min_idxs.size(0)\n",
    "        ensemble_poses = ensemble_poses.view(-1, self.num_candidates, 4)\n",
    "        best_poses = ensemble_poses[batch_idxs, min_idxs, :].detach()\n",
    "        \n",
    "        poses_diff = F.normalize(quatmul(best_poses, quatconj(student_poses)), dim=-1)\n",
    "        angle_diff = poses_diff[:, 0]\n",
    "        student_loss = (1 - angle_diff**2).sum() / min_idxs.size(0)\n",
    "        \n",
    "        return dict(\n",
    "            projection_loss=min_projection_loss,\n",
    "            student_loss=student_loss,\n",
    "            full_loss=min_projection_loss + self.student_weight * student_loss,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data\n",
    "\n",
    "We use splits and renders from authors of the paper (but we train on train + test and validate on val). There is an option in dataset to load camera positions instead of other views. We always load all 5 renders (for simplicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T09:19:58.757949Z",
     "start_time": "2019-12-18T09:18:01.838906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!wget --quiest --show-progress \"https://datasets.d2.mpi-inf.mpg.de/unsupervised-shape-pose/{DataBunch._ids[\"chairs\"]}-renders.tar.gz\"\n",
    "!wget --quiest --show-progress \"https://datasets.d2.mpi-inf.mpg.de/unsupervised-shape-pose/{DataBunch._ids[\"planes\"]}-renders.tar.gz\"\n",
    "!wget --quiest --show-progress \"https://datasets.d2.mpi-inf.mpg.de/unsupervised-shape-pose/{DataBunch._ids[\"cars\"]}-renders.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T09:22:25.108353Z",
     "start_time": "2019-12-18T09:21:41.751401Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!tar -xzf \"{DataBunch._ids[\"chairs\"]}-renders.tar.gz\"\n",
    "!tar -xzf \"{DataBunch._ids[\"planes\"]}-renders.tar.gz\"\n",
    "!tar -xzf \"{DataBunch._ids[\"cars\"]}-renders.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T09:24:38.680466Z",
     "start_time": "2019-12-18T09:24:38.357604Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!mv \"{DataBunch._ids[\"chairs\"]}\" data\n",
    "!mv \"{DataBunch._ids[\"planes\"]}\" data\n",
    "!mv \"{DataBunch._ids[\"cars\"]}\" data\n",
    "\n",
    "!rm \"{DataBunch._ids[\"chairs\"]}-renders.tar.gz\"\n",
    "!rm \"{DataBunch._ids[\"planes\"]}-renders.tar.gz\"\n",
    "!rm \"{DataBunch._ids[\"cars\"]}-renders.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pytorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T11:46:05.337133Z",
     "start_time": "2019-12-18T11:46:05.319417Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_models(path=\".\", shapenet_id=\"03001627\", split=\"train\"):\n",
    "    \"Read model paths from split file\"\n",
    "    path = Path(path)\n",
    "\n",
    "    assert split in (\"train\", \"valid\")\n",
    "    split = path/f\"{shapenet_id}.{split}\"\n",
    "    data = path/shapenet_id\n",
    "\n",
    "    with open(split) as models:\n",
    "        return [data/m.strip() for m in models]\n",
    "\n",
    "\n",
    "class Shapenet(Dataset):\n",
    "    \"Dataset with renders and views for shapenet category\"\n",
    "    def __init__(self, models, camera=True):\n",
    "        self.models = models\n",
    "        self.camera = camera\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        model = self.models[idx]\n",
    "        images = []\n",
    "        masks = []\n",
    "        cameras = []\n",
    "\n",
    "        for name in sorted(os.listdir(model)):\n",
    "            if name.startswith(\"render\"):\n",
    "                o = np.array(Image.open(model/name))\n",
    "                mask = o[..., -1].astype(np.float32) / 255.\n",
    "                img = o[..., :-1].astype(np.float32) / 255.\n",
    "                \n",
    "                images.append(torch.tensor(img).permute(2, 0, 1))\n",
    "                masks.append(torch.tensor(mask))\n",
    "                \n",
    "            if name.startswith(\"camera\"):\n",
    "                camera = loadmat(model/name)\n",
    "                cameras.append(quat_from_campos(camera[\"pos\"]))\n",
    "        \n",
    "        images = torch.stack(images)\n",
    "        masks = torch.stack(masks)\n",
    "        if self.camera: poses = torch.stack(cameras)\n",
    "        else:           poses = images\n",
    "\n",
    "        return images, poses, masks\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Collate function handles sampling one image for point cloud generation. `views` might be cameras or images (depends on dataset configuration, but either way it is some information about other views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T11:46:07.020457Z",
     "start_time": "2019-12-18T11:46:07.011539Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def multi_view_collate(batch):\n",
    "    \"Prepare batch with 1 image and n_poses masks and poses per item\"\n",
    "    bs = len(batch)\n",
    "    n_poses = batch[0][0].size(0)\n",
    "\n",
    "    idxs = torch.randint(0, n_poses, size=(bs,))\n",
    "    imgs, poses, masks = zip(*[(img[i], view, mask) for (img, view, mask), i in zip(batch, idxs)])\n",
    "\n",
    "    imgs = torch.stack(imgs)\n",
    "    poses = torch.cat(poses, dim=0)\n",
    "    masks = torch.cat(masks, dim=0)\n",
    "    \n",
    "    return imgs, poses, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Datasets and dataloaders all in one class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T11:46:08.288652Z",
     "start_time": "2019-12-18T11:46:08.277811Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class DataBunch():\n",
    "    _ids = {\n",
    "        \"chairs\": \"03001627\",\n",
    "        \"planes\": \"02691156\",\n",
    "        \"cars\": \"02958343\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, path, category=\"chairs\", batch_size=10, camera=True):\n",
    "        train = get_models(path, self._ids[category], \"train\")\n",
    "        valid = get_models(path, self._ids[category], \"valid\")\n",
    "        self.train_ds, self.valid_ds = Shapenet(train, camera), Shapenet(valid, camera)\n",
    "        self.train_dl = DataLoader(\n",
    "            self.train_ds, batch_size, \n",
    "            shuffle=True, collate_fn=multi_view_collate, drop_last=True, \n",
    "            pin_memory=torch.cuda.is_available(), num_workers=4,\n",
    "        )\n",
    "        self.valid_dl = DataLoader(\n",
    "            self.valid_ds, batch_size * 2, \n",
    "            shuffle=False, collate_fn=multi_view_collate, \n",
    "            pin_memory=torch.cuda.is_available(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to overfit one example and see what happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Overfit one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = SimpleModel(img_size=128, smooth_sigma=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.random.manual_seed(10)\n",
    "model = SimpleModel(img_size=128, smooth_sigma=3.0).cuda()\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "torch.random.manual_seed(10)\n",
    "imgs, cams, masks = next(iter(train_dl))\n",
    "\n",
    "imgs = imgs.cuda()\n",
    "cams = cams.cuda()\n",
    "masks = masks.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T12:40:17.492547Z",
     "start_time": "2019-12-04T12:39:40.981177Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feeedef353624c1b948e8780028cded5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-d11e8cf951f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtarg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-194-94c55c3b72b9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, imgs, cameras)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mpc\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mrepeat_tensor_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpc_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_views\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepeat_tensor_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_views\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mproj\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpc_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcameras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# store for visualizations and tests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-190-8d9d0e65c6e4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pc, rotation, scale)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;34m\"Project points `pc` to camera givne by `transform`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpc_camera_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mvoxels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpc_voxels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvox_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0msmooth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoxels_smooth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoxels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmoothing_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3eede7a1093e>\u001b[0m in \u001b[0;36mpc_voxels\u001b[0;34m(pc, size, eps)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mvoxels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrilinear_interp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoxels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3eede7a1093e>\u001b[0m in \u001b[0;36mtrilinear_interp\u001b[0;34m(pos)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrilinear_interp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mupdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mupdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mshift_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pbar = tqdm_notebook(range(1000))\n",
    "\n",
    "for i in pbar:\n",
    "    t1 = time.perf_counter()\n",
    "    proj = model(imgs, cams)\n",
    "    targ = F.interpolate(masks.unsqueeze(0), scale_factor=1/2, mode='bilinear', align_corners=False).squeeze()\n",
    "\n",
    "    loss = F.mse_loss(proj, targ, reduction='sum') / targ.size(0)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    dt = time.perf_counter() - t1\n",
    "\n",
    "    pbar.set_postfix(time=dt, loss=loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T12:03:46.565172Z",
     "start_time": "2019-12-18T12:03:46.560960Z"
    }
   },
   "outputs": [],
   "source": [
    "def loopy(dl):\n",
    "    \"Loop through dataloader indefinitley\"\n",
    "    while True:\n",
    "        for o in dl: yield o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T12:03:45.526347Z",
     "start_time": "2019-12-18T12:03:45.517285Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_params(model, step, keep_prob=(0.07, 1.0), sigma=(3.0, 0.2)):\n",
    "    \"Schedule model parameters linearly (dropout keep_prob and smoothing sigma)\"\n",
    "    assert 0 <= step <= 1\n",
    "\n",
    "    new_keep_prob = keep_prob[0] * (1 - step) + keep_prob[1] * step\n",
    "    new_sigma = sigma[0] * (1 - step) + sigma[1] * step\n",
    "    \n",
    "    model.pc_dropout.keep_prob = new_keep_prob\n",
    "    model.pc_projection.sigma  = torch.empty_like(model.pc_projection.sigma).fill_(new_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class for training models and capturing progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T13:06:22.628138Z",
     "start_time": "2019-12-18T13:06:22.594893Z"
    }
   },
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    \"Class for training a model\"\n",
    "    def __init__(self, path, data, model, loss, lr=1e-3, wd=0.001, seed=100):\n",
    "        torch.random.manual_seed(seed)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.path = Path(path)\n",
    "        if self.path.exists():\n",
    "            shutil.rmtree(self.path)\n",
    "        (self.path/\"models\").mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        self.train_writer = SummaryWriter(log_dir=self.path/\"logs\"/\"train\")\n",
    "        self.valid_writer = SummaryWriter(log_dir=self.path/\"logs\"/\"valid\")\n",
    "        self.valid_losses = []\n",
    "\n",
    "        self.data = data\n",
    "        self.model = model.to(self.device)\n",
    "        self.loss = loss\n",
    "        self.opt = torch.optim.AdamW(self.model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    def fit(self, steps=300_000, eval_every=10_000, vis_every=1000):\n",
    "        \"Train model for `steps` steps\"\n",
    "        pbar = tqdm(range(1, steps + 1), desc=\"Step\")\n",
    "        train_dl = loopy(self.data.train_dl)\n",
    "        \n",
    "        for step in pbar:\n",
    "            self.model.train()\n",
    "            adjust_params(model, step / steps)\n",
    "            self.step = step\n",
    "            self.imgs, self.poses, self.masks = next(train_dl)\n",
    "            self.one_batch()\n",
    "\n",
    "            if step % eval_every == 0:\n",
    "                self.model.eval()\n",
    "                with torch.no_grad():\n",
    "                    i=0\n",
    "                    for self.imgs, self.poses, self.masks in tqdm(self.data.valid_dl, leave=False):\n",
    "                        self.one_batch()\n",
    "                        i+=1\n",
    "                        if i == 3:\n",
    "                            break\n",
    "                    self.write_valid_losses()\n",
    "\n",
    "                torch.save(\n",
    "                    dict(model=self.model.state_dict(), opt=self.opt.state_dict(), step=self.step), \n",
    "                    self.path/\"models\"/f\"model_{self.step}.pth\"\n",
    "                )\n",
    "\n",
    "            if step % vis_every == 0:\n",
    "                self.model.eval()\n",
    "                imgs, poses, masks = self.data.valid_ds[10]\n",
    "                renders = generate_projections_img(self.model, imgs, poses, masks)\n",
    "                self.train_writer.add_images(\"renders\", renders, self.step)\n",
    "\n",
    "\n",
    "    def one_batch(self):\n",
    "        \"Run one batch of a model\"\n",
    "        device = self.device\n",
    "        imgs, poses, masks = self.imgs.to(device),self.poses.to(device),self.masks.to(device)\n",
    "\n",
    "        proj = self.model(imgs, poses)\n",
    "        loss = self.loss(proj, masks, training=self.model.training)\n",
    "        if not self.model.training:\n",
    "            self.valid_losses.append({key: l.item() for key, l in loss.items()})\n",
    "            return\n",
    "\n",
    "        loss['full_loss'].backward()\n",
    "        self.opt.step()\n",
    "        self.opt.zero_grad()\n",
    "        \n",
    "        for key, l in loss.items():\n",
    "            self.train_writer.add_scalar(key, l.item(), self.step)\n",
    "\n",
    "    def write_valid_losses(self):\n",
    "        \"Calculate means for all validation losses and write to tensorboard\"\n",
    "        means = defaultdict(int)\n",
    "        for loss in self.valid_losses:\n",
    "            for key, val in loss.items():\n",
    "                means[key] += val\n",
    "\n",
    "        for key in means.keys():\n",
    "            self.valid_writer.add_scalar(key, means[key] / len(self.valid_losses), self.step)\n",
    "            print(f\"{key}={means[key]/len(self.valid_losses):.3f}\", end=\" \")\n",
    "        print()\n",
    "        self.valid_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T13:06:24.107929Z",
     "start_time": "2019-12-18T13:06:23.781063Z"
    }
   },
   "outputs": [],
   "source": [
    "data = DataBunch(path=\"data\", batch_size=2, camera=False)\n",
    "learner = Learner(\"./test_flight\", data, UnsupervisedModel(), UnsupervisedLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T13:07:27.393972Z",
     "start_time": "2019-12-18T13:06:24.266428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42095e2d2acf4a08a3f05398a15563c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Step', max=20.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8334a0eac75a4549980804a4da9ed471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=170.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projection_loss=3159.980 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-b54bcbf10003>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvis_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-180-ac4442d3385d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, steps, eval_every, vis_every)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meval_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-180-ac4442d3385d>\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/point_clouds/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-154-1351f4ac1cfa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, imgs, poses)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mpc\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mrepeat_tensor_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpc_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_candidates\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_views\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepeat_tensor_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_candidates\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_views\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpc_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble_poses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mproj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble_poses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_poses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/point_clouds/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-78174b4a2e1a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pc, rotation, scale)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0msmooth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoxels_smooth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoxels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmoothing_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrc_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mproj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-22f5a389fa73>\u001b[0m in \u001b[0;36mdrc_prob\u001b[0;34m(voxels, clip_val)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.fit(steps=20, eval_every=2, vis_every=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.random.manual_seed(10)\n",
    "model = SimpleModel(img_size=128, smooth_sigma=3.0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T20:31:01.519060Z",
     "start_time": "2019-12-04T20:31:01.107727Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(open(\"../camera_supervision/model_66000.pth\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T20:50:16.004880Z",
     "start_time": "2019-12-04T20:50:14.972917Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['model']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T20:33:50.643807Z",
     "start_time": "2019-12-04T20:33:50.614960Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "imgs, cams, masks = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "imgs = imgs.cuda()\n",
    "cams = cams.cuda()\n",
    "masks = masks.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T20:35:01.824789Z",
     "start_time": "2019-12-04T20:35:01.801898Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pc, scale = model.decoder(model.encoder.forward(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "voxels = pc_voxels(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kernels = smoothing_kernel(pc.new([1.0]), 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "smooth_old = voxels_smooth_old(voxels, kernels).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "smooth = voxels_smooth(voxels, kernels).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(smooth, smooth_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 ms, sys: 0 ns, total: 12.2 ms\n",
      "Wall time: 11.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "voxels.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 65, 64, 64])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drc_prob(voxels.squeeze(0))[:, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T20:35:14.646855Z",
     "start_time": "2019-12-04T20:35:14.626753Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pc_np = pc.squeeze().detach().cpu().numpy()\n",
    "pcd = o3.geometry.PointCloud()\n",
    "pcd.points = o3.utility.Vector3dVector(pc_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T20:37:18.996720Z",
     "start_time": "2019-12-04T20:37:18.714202Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vis = o3.JVisualizer()\n",
    "vis.add_geometry(pcd)\n",
    "vis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T20:33:52.469836Z",
     "start_time": "2019-12-04T20:33:51.049204Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform 0.001497567000114941 Voxels 0.008974589000899869 Smoothing 0.000893971000550664 Probability 0.0003270800007157959 Projection 0.00021775100049126195\n",
      "Projection 0.01271116299994901\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=664x400 at 0x7F053C545CC0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.to_pil_image(generate_projections_img(model, img.cuda(), cam.cuda(), mask))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
